{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c9108b",
   "metadata": {},
   "source": [
    "Importing Libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e0625a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c21687",
   "metadata": {},
   "source": [
    "Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "443478d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Breast Cancer Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2c17b3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e029549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72eb4ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2959feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 2:32].values\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d79ae1",
   "metadata": {},
   "source": [
    "Encoding Categorical values using Label Encoding \n",
    "A Label Encoder is used to convert labels into numeric form i.e. machine readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82e0c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f61d83",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "88578e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66898bed",
   "metadata": {},
   "source": [
    "Feature Scaling using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e4e8855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "t = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcdfdb1",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3a7dedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of testing data:  0.9736842105263158\n",
      "The running time:  0.8795151710510254\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "output = rfc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, output) \n",
    "print(\"The accuracy of testing data: \",accuracy)\n",
    "print(\"The running time: \",time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "803377da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[66  1]\n",
      " [ 2 45]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        67\n",
      "           1       0.98      0.96      0.97        47\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,output)\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\",classification_report(y_test, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf6ee3",
   "metadata": {},
   "source": [
    "**Bagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5ebb1",
   "metadata": {},
   "source": [
    "Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce variance within a noisy dataset. In bagging, a random sample of data in a training set is selected with replacement—meaning that the individual data points can be chosen more than once. After several data samples are generated, these weak models are then trained independently, and depending on the type of task—regression or classification, for example the average or majority of those predictions yield a more accurate estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110f890",
   "metadata": {},
   "source": [
    "Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b95ab41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cb1e18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of testing data:  0.956140350877193\n",
      "The running time:  3.0861871242523193\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(n_estimators=50)\n",
    "bag.fit(X_train, y_train)\n",
    "output = bag.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, output) \n",
    "print(\"The accuracy of testing data: \",accuracy)\n",
    "print(\"The running time: \",time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9cd5b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[64  3]\n",
      " [ 2 45]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96        67\n",
      "           1       0.94      0.96      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,output)\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\",classification_report(y_test, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584beea4",
   "metadata": {},
   "source": [
    "**Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6fef2",
   "metadata": {},
   "source": [
    "Boosting is an ensemble modeling technique that attempts to build a strong classifier from the number of weak classifiers. It is done by building a model by using weak models in series. Firstly, a model is built from the training data. Then the second model is built which tries to correct the errors present in the first model. This procedure is continued and models are added until either the complete training data set is predicted correctly or the maximum number of models are added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af4300",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a45eaa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c5c91bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of testing data:  0.9824561403508771\n",
      "The running time:  6.199452638626099\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier(n_estimators=150,random_state=1)\n",
    "gbm.fit(X_train, y_train)\n",
    "output = gbm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, output) \n",
    "print(\"The accuracy of testing data: \",accuracy)\n",
    "print(\"The running time: \",time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cf23bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[66  1]\n",
      " [ 1 46]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        67\n",
      "           1       0.98      0.98      0.98        47\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,output)\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\",classification_report(y_test, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c968401",
   "metadata": {},
   "source": [
    "Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33346014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightgbm import  LGBMClassifier as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5ba51f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of testing data:  0.9824561403508771\n",
      "The running time:  7.198002338409424\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(n_estimators=200,random_state=1).fit(X_train, y_train)\n",
    "lgb.fit(X_train, y_train)\n",
    "output = lgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, output) \n",
    "print(\"The accuracy of testing data: \",accuracy)\n",
    "print(\"The running time: \",time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72586679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[67  0]\n",
      " [ 2 45]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        67\n",
      "           1       1.00      0.96      0.98        47\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,output)\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\",classification_report(y_test, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c17071",
   "metadata": {},
   "source": [
    "XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e8437d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d86abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of testing data:  0.9824561403508771\n",
      "The running time:  9.258988618850708\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100,random_state=1,eval_metric='mlogloss').fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "output = xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, output) \n",
    "print(\"The accuracy of testing data: \",accuracy)\n",
    "print(\"The running time: \",time()-t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "07109851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[67  0]\n",
      " [ 2 45]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        67\n",
      "           1       1.00      0.96      0.98        47\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,output)\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\",classification_report(y_test, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2088f6",
   "metadata": {},
   "source": [
    "**Stacking**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a164139",
   "metadata": {},
   "source": [
    "Stacking (a.k.a Stack Generalization) is an ensemble technique that uses meta-learning for generating predictions. It can harness the capabilities of well-performing as well as weakly-performing models on a classification or regression task and make predictions with better performance than any other single model in the ensemble.\n",
    "\n",
    "It is an extended form of the Model Averaging Ensemble technique, where multiple sub-models contribute equally or according to their performance weights to a combined prediction. In Stacking, an entirely new model to trained to combine the contributions from each submodel and produce the best predictions. This final model is said to be stacked on top of the others, hence the name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece681a",
   "metadata": {},
   "source": [
    "Level 1 Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef5e52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e71f96f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of testing data:  0.9649122807017544\n",
      "The running time:  4.741440057754517\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lf = [('xgb',XGBClassifier(n_estimators=400,random_state=1,eval_metric='mlogloss')),('rfc',RandomForestClassifier()),('knn',  KNeighborsClassifier()\n",
    ")]\n",
    "clf = StackingClassifier( estimators = lf,final_estimator = DecisionTreeClassifier())\n",
    "t = time()\n",
    "clf.fit(X_train, y_train)\n",
    "output = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, output) \n",
    "print(\"The accuracy of testing data: \",accuracy)\n",
    "print(\"The running time: \",time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "10ba5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[67  0]\n",
      " [ 4 43]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        67\n",
      "           1       1.00      0.91      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,output)\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\\n\",classification_report(y_test, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049816ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
